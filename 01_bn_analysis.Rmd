---
title: "Ssuis_Analysis-Manuscript"
author: "Brittany L Morgan Bustamante"
date: "Updated: 2025-12-17"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE,
                      dev = "cairo_pdf")

# libraries
library(bnlearn)
library(ggplot2)
library(tidyverse)
library(reshape2)
library(readxl)
library(Rgraphviz)

# import data
suis.df <- read_excel("/Users/brittanymorgan/Library/Mobile Documents/com~apple~CloudDocs/Documents/School/UC Davis/GSR Summer 2021/Data/suis_BNA_manuscript_data.xlsx")

# glimpse(suis.df)
```

## 1. Data Wrangling

```{r}
# subset data
## removed for system confidentiality

# isolate identifying variables
suis2 <- suis %>%
  dplyr::select(source, result_name, interpretation,, 
                site_name, siteID, yearrec, accessionID, animal_tag) %>%
  distinct(site_name, siteID, accessionID, animal_tag, yearrec) %>%
  dplyr::mutate(sampleflag = row_number())

# long to wide
suis3 <- suis %>%
    left_join(suis2, c("site_name", "siteID", "accessionID", "yearrec",
                            "animal_tag")) %>%
    dplyr::select(sampleflag, source, result_name, interpretation, 
                  site_name, siteID, yearrec, accessionID, animal_tag) %>%
  pivot_wider(names_from = result_name, values_from = c(interpretation))

# isolate identifying variables - sensitivity analysis
sens_suis2 <- suis %>%
  dplyr::select(source, result_name, sens_interpretation,, 
                site_name, siteID, yearrec, accessionID, animal_tag) %>%
  distinct(site_name, siteID, accessionID, animal_tag, yearrec) %>%
  dplyr::mutate(sampleflag = row_number())

# long to wide - sensitivity analysis
sens_suis3 <- suis %>%
    left_join(sens_suis2, c("site_name", "siteID", "accessionID", "yearrec",
                            "animal_tag")) %>%
    dplyr::select(sampleflag, source, result_name, sens_interpretation, 
                  site_name, siteID, yearrec, accessionID, animal_tag) %>%
  pivot_wider(names_from = result_name, values_from = c(sens_interpretation))
```

## 2. Descriptive Statistics

```{r}
MICresults <- suis.df %>%
  group_by(source, result_name, interpretation) %>%
  dplyr::summarize(n_samples = n()) %>%
  ungroup()
```

Will remove Ampicillin, Florfenicol, and Trimethoprim-Sulphamethoxazole because less than ten isolates showed phenotypic susceptibility/resistance for each.

## 3. Analytic Dataframe

```{r}
# select AMDs with large enough cell counts
library(gtsummary)

suis.amd <- suis3 %>%
  select(siteID, Ceftiofur, Chlortetracycline, Clindamycin, Enrofloxacin,
         Gentamicin, Neomycin, Oxytetracycline, Penicillin, Spectinomycin,
         Sulphadimethoxine, Tetracycline, Tiamulin, Tilmicosin)
# suis.amd %>% tbl_summary()

# create factors for variables
suis.amd$siteID <- (as.factor(suis.amd$siteID))
suis.amd$CEF <- (as.factor(suis.amd$Ceftiofur))
suis.amd$ENR <- (as.factor(suis.amd$Enrofloxacin))
suis.amd$GEN <- (as.factor(suis.amd$Gentamicin))
suis.amd$NEO <- (as.factor(suis.amd$Neomycin))
suis.amd$PEN <- (as.factor(suis.amd$Penicillin))
suis.amd$SPC <- (as.factor(suis.amd$Spectinomycin))
suis.amd$SUL <- (as.factor(suis.amd$Sulphadimethoxine))
suis.amd$TIA <- (as.factor(suis.amd$Tiamulin))
suis.amd$TIL <- (as.factor(suis.amd$Tilmicosin))
suis.amd$CHL <- (as.factor(suis.amd$Chlortetracycline))
suis.amd$CLN <- (as.factor(suis.amd$Clindamycin))
suis.amd$OXY <- (as.factor(suis.amd$Oxytetracycline))
suis.amd$TET <- (as.factor(suis.amd$Tetracycline))

# keep only variables for analysis
df_analyze <- as.data.frame(suis.amd) %>%
  select(siteID, CEF, ENR, GEN, NEO, PEN, SPC, SUL, TIA, TIL, CHL, CLN, OXY, TET)

# total number of sites
sites <- distinct(suis3, siteID)

# drop sites with no retained data
df_analyze <- df_analyze %>%
  mutate(siteID = droplevels(siteID))
```

## 4. Bayesian Network Analysis

Will use the structure learning algorithm, tabu. Tabu is a score-based algorithm, a modified greedy hill-climbing search. Score-based algorithms use goodness-of-fit scores as objective functions to maximize fit score (in this case, BIC).

To smooth over missing data, *Structural.em* is used. Structural.em is the "Expectation-Maximization" algorithm, an iterative procedure computing the expected sufficient statistics conditional on the observed data using belief propagation, then applying complete-data learning methods using expected sufficient statistic. EM starts from the model and estimates/identifies the sufficient statistics needed to estimate its parameters and completes those statistics by averaging over the missing values.

Two methods of imputation will be tested: parents and Bayes. Parents method computes predicted values by plugging in new values for the parents node in the local probability distribution of "node" extracted from "fitted" DAG. Bayes method computes predicted values by averaging likelihood weighting simulations performed using all the nodes as evidence. The default number of random samples drawn is 500.

To account for clustering of observations at the siteID level, we create tiers that allow siteID to be a background or context variable, now be the child of any lower-level variable (blocklist) and allows the lower-level variables to connect among themselves.

```{r}
# create levels
amd_vars <- c("CEF", "ENR", "GEN", "NEO", "PEN", "SPC", "SUL", 
              "TIA", "TIL", "CHL", "CLN", "OXY", "TET")

tiers <- list(c("siteID"), amd_vars)

bl <- tiers2blacklist(tiers)
```

```{r}
library(bnlearn)

# impute with parents method
tabu <- structural.em(df_analyze, maximize = "tabu", 
                          maximize.args = list(score = "bic",
                                               blacklist = bl), 
                          impute = "parents", return.all = TRUE)

# impute with bayes method
tabu2 <- structural.em(df_analyze, maximize = "tabu", 
                           maximize.args = list(score = "bic",
                                                blacklist = bl),
                           impute = "bayes-lw", return.all = TRUE)
```

Bootstrap analysis identifies which arcs are the strongest and most consistent. Will run 10,000 iterations. For each sample, the previous steps are repeated, and a separate network is learned using the score-based learning algorithm and BIC test. The *boot.strength* function returns the strength of connection for each pair of nodes (i.e., how frequently the connection is observed). This information is used to build a consensus network, defined as a network containing arcs having a strength \>50%.

There will be lots of warnings that pop up because some sites have few data points and it just means some bootstrap samples donâ€™t include all sites. So, we suppress the warnings

```{r}
# bootstrap - parents
boot = suppressWarnings(
  boot.strength(tabu$imputed, R = 10000, algorithm = "tabu", 
                        algorithm.args = list(score = "bic",
                                              blacklist = bl)))

# take arcs with strength of threshold and return average consensus network - parents
avg = averaged.network(boot, threshold = 0.5)
graphviz.plot(avg, shape = "ellipse", main = NULL, sub = "Bayesian Network Analysis - S. suis isolates w/ parents imputation")

# plot DAG with strength of association information - parents
strength.plot(avg, boot, shape = "ellipse")
```

```{r}
# bootstrap - bayes
boot2 = suppressWarnings(boot.strength(
  tabu2$imputed, R = 10000, algorithm = "tabu", 
                        algorithm.args = list(score = "bic",
                                              blacklist = bl)))

# take arcs with strength of threshold and return average consensus network - bayes
avg2 = averaged.network(boot2, threshold = 0.5)
graphviz.plot(avg2, shape = "ellipse", main = NULL, sub = "Bayesian Network Analysis - S. suis isolates w/ bayes imputation")

# plot DAG with strength of association information - bayes
strength.plot(avg2, boot2, shape = "ellipse")
```

Undirected strength plot using Bayes imputation method for publication

```{r}
library(igraph)
library(ggraph)
library(scales)

# convert boot result + averaged network into an undirected graph
nodes_df <- data.frame(name = nodes(avg2))
boot_df  <- as.data.frame(boot2) 
avg_arcs <- as.data.frame(arcs(avg2)) 

edges <- avg_arcs %>%
  left_join(boot_df[, c("from", "to", "strength")],
            by = c("from", "to"))

g <- graph_from_data_frame(edges, directed = FALSE, vertices = nodes_df) 

# strength plot without arrows
set.seed(123)  # for reproducible layout

# create layout
lay <- create_layout(g, layout = "nicely")

# find the row corresponding to siteID
idx_site <- which(lay$name == "siteID")

# compute a horizontal center for the main network (all non-siteID nodes)
center_x <- mean(lay$x[lay$name != "siteID"])

# put siteID above the rest
lay$x[idx_site] <- center_x
lay$y[idx_site] <- max(lay$y) + 0.35

# plot
lay <- ggraph(lay) +
  geom_edge_link(aes(width = strength, alpha = strength),
                 color = "black") +
  geom_node_circle(aes(r = 0.3),
                   fill = "white",
                   color = "black",
                   size = 0.2) +
  geom_node_text(aes(label = name),
                 size = 3.5) +
  scale_edge_width(range = c(0.2, 2)) +
  scale_edge_alpha(range = c(0.3, 1)) +
  guides(edge_width = "none", edge_alpha = "none") +
  theme_graph()

# ggsave("full_network_plot.png", width = 8, height = 6, dpi = 300)

ggsave("full_network_plot.tif", lay)
```

## 5. Parameter Learning

```{r}
# fit the parameters - maximum likelihood method
fit = bn.fit(avg, df_analyze, method = "bayes")
```

```{r}
# Probability table
# fit
```

```{r}
set.seed(112)

# PEN - GEN
cpquery(fit, (PEN =="Resistant"), GEN == "Resistant")
cpquery(fit, (PEN =="Resistant"), GEN == "Susceptible")
cpquery(fit, (PEN =="Susceptible"), GEN == "Resistant")
cpquery(fit, (PEN =="Susceptible"), GEN == "Susceptible")
```

```{r}
set.seed(134)
cpquery(fit, (GEN =="Resistant"), PEN == "Resistant")
cpquery(fit, (GEN =="Resistant"), PEN == "Susceptible")
cpquery(fit, (GEN =="Susceptible"), PEN == "Resistant")
cpquery(fit, (GEN =="Susceptible"), PEN == "Susceptible")
```

```{r}
set.seed(113)

# PEN - CEF
cpquery(fit, (PEN =="Resistant"), CEF == "Resistant")
cpquery(fit, (PEN =="Resistant"), CEF == "Susceptible")
cpquery(fit, (PEN =="Susceptible"), CEF == "Resistant")
cpquery(fit, (PEN =="Susceptible"), CEF == "Susceptible")
```

```{r}
set.seed(114)

# SUL - PEN
cpquery(fit, (SUL =="Resistant"), PEN == "Resistant")
cpquery(fit, (SUL =="Resistant"), PEN == "Susceptible")
cpquery(fit, (SUL =="Susceptible"), PEN == "Resistant")
cpquery(fit, (SUL =="Susceptible"), PEN == "Susceptible")
```

```{r}
set.seed(114)

# SUL - PEN - TIL
cpquery(fit, (SUL =="Resistant"), PEN == "Resistant" & TIL == "Resistant")
cpquery(fit, (SUL =="Resistant"), PEN == "Resistant" & TIL == "Susceptible")
cpquery(fit, (SUL =="Resistant"), PEN == "Susceptible" & TIL == "Resistant")
cpquery(fit, (SUL =="Resistant"), PEN == "Susceptible" & TIL == "Susceptible")
cpquery(fit, (SUL =="Susceptible"), PEN == "Resistant" & TIL == "Susceptible")
cpquery(fit, (SUL =="Susceptible"), PEN == "Susceptible" & TIL == "Susceptible")
cpquery(fit, (SUL =="Resistant"), PEN == "Susceptible" | TIL == "Susceptible")
```

```{r}
set.seed(114)

# PEN - SUL
cpquery(fit, (PEN =="Resistant"), SUL == "Resistant")
cpquery(fit, (PEN =="Resistant"), SUL == "Susceptible")

cpquery(fit, (PEN =="Resistant"), SUL == "Resistant" & TIL == "Resistant")
cpquery(fit, (PEN =="Resistant"), SUL == "Susceptible" & TIL == "Resistant")
cpquery(fit, (PEN =="Resistanct"), SUL == "Resistant" & TIL == "Susceptible")
cpquery(fit, (PEN =="Resistant"), SUL == "Susceptible" & TIL == "Susceptible")

cpquery(fit, (SUL =="Resistant"), TIL == "Resistant" & PEN == "Susceptible")
```

```{r}
set.seed(115)

# PEN - TIA
cpquery(fit, (TIA =="Resistant"), PEN == "Resistant")
cpquery(fit, (TIA =="Resistant"), PEN == "Susceptible")
cpquery(fit, (TIA =="Susceptible"), PEN == "Resistant")
cpquery(fit, (TIA =="Susceptible"), PEN == "Susceptible")

cpquery(fit, (PEN =="Resistant"), TIA == "Resistant")
cpquery(fit, (PEN =="Resistant"), TIA == "Susceptible")
cpquery(fit, (PEN =="Susceptible"), TIA == "Susceptible")
```

```{r}
set.seed(167)
cpquery(fit, (TIA =="Resistant"), PEN == "Resistant" & SPC == "Resistant")
cpquery(fit, (TIA =="Resistant"), PEN == "Susceptible" & SPC == "Resistant")
cpquery(fit, (TIA =="Resistant"), PEN == "Resistant" & SPC == "Susceptible")
cpquery(fit, (TIA =="Susceptible"), PEN == "Susceptible" & SPC == "Susceptible")
```

```{r}
set.seed(194)

# CLN - TIA
cpquery(fit, (CLN =="Resistant"), TIA == "Resistant")
cpquery(fit, (TIA =="Resistant"), CLN == "Resistant")
cpquery(fit, (TIA =="Susceptible"), CLN == "Suseptible")

cpquery(fit, (TIA =="Resistant"), PEN == "Resistant" & CLN == "Resistant")
cpquery(fit, (TIA =="Resistant"), PEN == "Susceptible" & CLN == "Resistant")
cpquery(fit, (TIA =="Resistant"), PEN == "Resistant" & CLN == "Susceptible")
cpquery(fit, (TIA =="Susceptible"), PEN == "Resistant" & CLN == "Susceptible")
cpquery(fit, (TIA =="Susceptible"), PEN == "Susceptible" & CLN == "Susceptible")
```

```{r}
set.seed(116)

# SUL - TIL
cpquery(fit, (TIL =="Resistant"), SUL == "Resistant")
cpquery(fit, (TIL =="Resistant"), SUL == "Susceptible")
cpquery(fit, (TIL =="Susceptible"), SUL == "Resistant")
cpquery(fit, (TIL =="Susceptible"), SUL == "Susceptible")

cpquery(fit, (TIL =="Resistant"), SUL == "Resistant" & CLN == "Susceptible")
cpquery(fit, (TIL =="Resistant"), SUL == "Resistant" & CLN == "Resistant")
```

```{r}
set.seed(117)

# TIL - CLN
cpquery(fit, (TIL =="Resistant"), CLN == "Resistant")
cpquery(fit, (TIL =="Resistant"), CLN == "Susceptible")
cpquery(fit, (TIL =="Susceptible"), CLN == "Resistant")
cpquery(fit, (TIL =="Susceptible"), CLN == "Susceptible")

cpquery(fit, (TIL =="Resistant"), CLN == "Resistant" & SUL == "Resistant")
cpquery(fit, (TIL =="Resistant"), CLN == "Susceptible" & SUL == "Resistant")
cpquery(fit, (TIL =="Resistant"), CLN == "Resistant" & SUL == "Susceptible")

# CLN - TIL
cpquery(fit, (CLN =="Resistant"), TIL == "Resistant")
cpquery(fit, (CLN =="Resistant"), TIL == "Susceptible")
cpquery(fit, (CLN =="Susceptible"), TIL == "Resistant")
cpquery(fit, (CLN =="Susceptible"), TIL == "Susceptible")
```

```{r}
set.seed(118)

# TIA - SPC
cpquery(fit, (TIA =="Resistant"), SPC == "Resistant")
cpquery(fit, (TIA =="Resistant"), SPC == "Susceptible")
cpquery(fit, (TIA =="Susceptible"), SPC == "Resistant")
cpquery(fit, (TIA =="Susceptible"), SPC == "Susceptible")

cpquery(fit, (SPC =="Resistant"), TIA == "Resistant")
cpquery(fit, (SPC =="Susceptible"), TIA == "Susceptible")
```

```{r}
set.seed(119)

# CLN - TET
cpquery(fit, (CLN =="Resistant"), TET == "Resistant")
cpquery(fit, (CLN =="Resistant"), TET == "Susceptible")
cpquery(fit, (CLN =="Susceptible"), TET == "Resistant")
cpquery(fit, (CLN =="Susceptible"), TET == "Susceptible")

cpquery(fit, (TET =="Resistant"), CLN == "Resistant")
cpquery(fit, (TET =="Resistant"), CLN == "Susceptible")
```

```{r}
set.seed(120)

# SPC - CEF
cpquery(fit, (SPC =="Resistant"), CEF == "Resistant")
cpquery(fit, (SPC =="Resistant"), CEF == "Susceptible")
cpquery(fit, (SPC =="Susceptible"), CEF == "Resistant")
cpquery(fit, (SPC =="Susceptible"), CEF == "Susceptible")

# CEF - SPC
cpquery(fit, (CEF =="Resistant"), SPC == "Resistant")
cpquery(fit, (CEF =="Resistant"), SPC == "Susceptible")
cpquery(fit, (CEF =="Susceptible"), SPC == "Resistant")
cpquery(fit, (CEF =="Susceptible"), SPC == "Susceptible")
```

```{r}
set.seed(121)

# OXY - CHL
cpquery(fit, (OXY =="Resistant"), CHL == "Resistant")
cpquery(fit, (OXY =="Resistant"), CHL == "Susceptible")
cpquery(fit, (OXY =="Susceptible"), CHL == "Resistant")
cpquery(fit, (OXY =="Susceptible"), CHL == "Susceptible")

cpquery(fit, (OXY =="Resistant"), CHL == "Resistant" & TIL == "Resistant")
cpquery(fit, (OXY =="Resistant"), CHL == "Resistant" & TIL == "Susceptible")

cpquery(fit, (CHL =="Resistant"), OXY == "Resistant")
cpquery(fit, (CHL =="Resistant"), OXY == "Susceptible")
```

```{r}
set.seed(122)

# CEF - PEN
cpquery(fit, (CEF =="Resistant"), PEN == "Resistant")
cpquery(fit, (CEF =="Susceptible"), PEN == "Susceptible")
```

## 6. Sensitivity Analysis

Same steps as above, but grouping intermediate with resistant rather than susceptible

```{r}
# select AMDs with large enough cell counts
sens_suis.amd <- sens_suis3 %>%
  select(siteID, Ceftiofur, Chlortetracycline, Clindamycin, Enrofloxacin,
         Gentamicin, Neomycin, Oxytetracycline, Penicillin, Spectinomycin,
         Sulphadimethoxine, Tetracycline, Tiamulin, Tilmicosin)

# create factors for variables
sens_suis.amd$siteID <- (as.factor(sens_suis.amd$siteID))
sens_suis.amd$CEF <- (as.factor(sens_suis.amd$Ceftiofur))
sens_suis.amd$ENR <- (as.factor(sens_suis.amd$Enrofloxacin))
sens_suis.amd$GEN <- (as.factor(sens_suis.amd$Gentamicin))
sens_suis.amd$NEO <- (as.factor(sens_suis.amd$Neomycin))
sens_suis.amd$PEN <- (as.factor(sens_suis.amd$Penicillin))
sens_suis.amd$SPC <- (as.factor(sens_suis.amd$Spectinomycin))
sens_suis.amd$SUL <- (as.factor(sens_suis.amd$Sulphadimethoxine))
sens_suis.amd$TIA <- (as.factor(sens_suis.amd$Tiamulin))
sens_suis.amd$TIL <- (as.factor(sens_suis.amd$Tilmicosin))
sens_suis.amd$CHL <- (as.factor(sens_suis.amd$Chlortetracycline))
sens_suis.amd$CLN <- (as.factor(sens_suis.amd$Clindamycin))
sens_suis.amd$OXY <- (as.factor(sens_suis.amd$Oxytetracycline))
sens_suis.amd$TET <- (as.factor(sens_suis.amd$Tetracycline))

# keep only variables for analysis
sensitivity <- as.data.frame(sens_suis.amd) %>%
  select(siteID, CEF, ENR, GEN, NEO, PEN, SPC, SUL, TIA, TIL, CHL, CLN, OXY, TET)
```

```{r}
# impute with bayes method
tabu2_sens <- structural.em(sensitivity, maximize = "tabu", 
                           maximize.args = list(score = "bic",
                                                blacklist = bl),
                           impute = "bayes-lw", return.all = TRUE)

# bootstrap - parents
boot_sens = suppressWarnings(boot.strength(tabu2_sens$imputed, R = 10000, 
                                               algorithm = "tabu", 
                        algorithm.args = list(score = "bic", blacklist = bl)))

# take arcs with strength of threshold and return average consensus network - parents
avg_sens = averaged.network(boot_sens, threshold = 0.5)
graphviz.plot(avg_sens, shape = "ellipse", main = NULL, sub = "Bayesian Network Analysis - S. suis isolates w/ parents imputation")

# plot DAG with strength of association information - parents
strength.plot(avg_sens, boot_sens, shape = "ellipse")

# bootstrap - bayes
boot2_sens = boot.strength(tabu2_sens$imputed, R = 10000, algorithm = "tabu", 
                        algorithm.args = list(score = "bic"))

# take arcs with strength of threshold and return average consensus network - bayes
avg2_sens = averaged.network(boot2_sens, threshold = 0.5)
graphviz.plot(avg2_sens, shape = "ellipse", main = NULL, sub = "Bayesian Network Sesitivity Analysis - S. suis isolates w/ bayes imputation")

# plot DAG with strength of association information - bayes
strength.plot(avg2_sens, boot2_sens, shape = "ellipse")
```

```{r}
# compare graphs
graphviz.compare(avg2, avg2_sens,
                 shape = "ellipse")
```

## 7. Subnetworks

```{r}
# df
yearly <- suis3 %>%
  select(yearrec, siteID, Ceftiofur, Chlortetracycline, Clindamycin, Enrofloxacin,
         Gentamicin, Neomycin, Oxytetracycline, Penicillin, Spectinomycin, 
         Sulphadimethoxine, Tetracycline, Tiamulin, Tilmicosin)
# yearly %>% tbl_summary()

# will combine 2014-2018, and 2019-2021
```

```{r}
# create factors for variables
yearly$siteID <- (as.factor(suis3$siteID))
yearly$CEF <- (as.factor(suis3$Ceftiofur))
yearly$CHL <- (as.factor(suis3$Chlortetracycline))
yearly$CLN <- (as.factor(suis3$Clindamycin))
yearly$ENR <- (as.factor(suis3$Enrofloxacin))
yearly$GEN <- (as.factor(suis3$Gentamicin))
yearly$NEO <- (as.factor(suis3$Neomycin))
yearly$OXY <- (as.factor(suis3$Oxytetracycline))
yearly$PEN <- (as.factor(suis3$Penicillin))
yearly$SPC <- (as.factor(suis3$Spectinomycin))
yearly$SUL <- (as.factor(suis3$Sulphadimethoxine))
yearly$TET <- (as.factor(suis3$Tetracycline))
yearly$TIA <- (as.factor(suis3$Tiamulin))
yearly$TIL <- (as.factor(suis3$Tilmicosin))
yearly$year <- factor(suis3$yearrec, order = TRUE,
                          levels = c(2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021),
                          labels = c("2014-2018", "2014-2018", "2014-2018", "2014-2018", 
                                     "2014-2018", "2019-2021", "2019-2021", "2019-2021"))

# keep only variables for analysis
year.analyze <- as.data.frame(yearly) %>%
  select(siteID, CEF, CHL, CLN, ENR, GEN, NEO, OXY, PEN, SPC, SUL, TET, TIA, TIL, year)

year.tbl <- year.analyze %>%
  select(siteID, year, CEF, CHL, CLN, ENR, GEN, NEO, OXY, PEN, SPC, SUL, TET, TIA, TIL) %>%
  tbl_summary(
    by = year)
```

```{r}
# split by year
analyze.2014 <- year.analyze %>%
  filter(year == "2014-2018") %>%
  select(-year)

analyze.2019 <- year.analyze %>%
  filter(year == "2019-2021") %>%
  select(-year)
```

```{r}
# table summary 2014-2018
# analyze.2014 %>% tbl_summary()
```

```{r}
# table summary 2019-2021
# analyze.2019 %>% tbl_summary()
```

Build network for each year using Bayes method imputation and structural.em

```{r}
# 2014-2018
graph.2014 <- structural.em(analyze.2014, maximize = "tabu", 
                            maximize.args = list(score = "bic",
                                                 blacklist = bl),
                            impute = "bayes-lw", return.all = TRUE)

# bootstrap
boot.2014 = boot.strength(graph.2014$imputed, R = 10000, algorithm = "tabu", 
                        algorithm.args = list(score = "bic",
                                              blacklist = bl))

# take arcs with strength of threshold and return average consensus network - bayes
avg.2014 = averaged.network(boot.2014, threshold = 0.5)

strength.plot(avg.2014, boot.2014, shape = "ellipse")
```

```{r}
# fit the parameters - maximum likelihood method
fit.2014 = bn.fit(avg.2014, analyze.2014, method = "bayes")

# 2014-2018 probability table
fit.2014
```

```{r}
# 2019-2021
graph.2019 <- structural.em(analyze.2019, maximize = "tabu", 
                            maximize.args = list(score = "bic",
                                                 blacklist = bl),
                            impute = "bayes-lw", return.all = TRUE)

# bootstrap
boot.2019 = boot.strength(graph.2019$imputed, R = 10000, algorithm = "tabu", 
                        algorithm.args = list(score = "bic",
                                              blacklist = bl))

# take arcs with strength of threshold and return average consensus network - bayes
avg.2019 = averaged.network(boot.2019, threshold = 0.5)

strength.plot(avg.2019, boot.2019, shape = "ellipse")
```

```{r}
# fit the parameters - maximum likelihood method
fit.2019 = bn.fit(avg.2019, analyze.2019, method = "bayes")

# 2019-2021 probability table
fit.2019
```

Combine graphs for visual comparison

```{r}
graphviz.compare(avg.2014, avg.2019, shape = "ellipse", 
                 main= c("averaged DAG - 2014-2018",
                         "averaged DAG - 2019-2021"))
```

remove arc directions for publication

```{r}
## 2014-2018

# convert boot result + averaged network into an undirected graph
nodes_df <- data.frame(name = nodes(avg.2014))
boot_df  <- as.data.frame(boot.2014) 
avg_arcs <- as.data.frame(arcs(avg.2014)) 

edges <- avg_arcs %>%
  left_join(boot_df[, c("from", "to", "strength")],
            by = c("from", "to"))

g <- graph_from_data_frame(edges, directed = FALSE, vertices = nodes_df) 

# strength plot without arrows
set.seed(123)  # for reproducible layout

# create layout
lay <- create_layout(g, layout = "nicely")

# find the row corresponding to siteID
idx_site <- which(lay$name == "siteID")

# compute a horizontal center for the main network (all non-siteID nodes)
center_x <- mean(lay$x[lay$name != "siteID"])

# put siteID above the rest
lay$x[idx_site] <- center_x
lay$y[idx_site] <- max(lay$y) + 0.85
# plot
ggraph(lay) +
  geom_edge_link(aes(width = strength, alpha = strength),
                 color = "black") +
  geom_node_circle(aes(r = 0.3),
                   fill = "white",
                   color = "black",
                   size = 0.2) +
  geom_node_text(aes(label = name),
                 size = 3.5) +
  scale_edge_width(range = c(0.2, 2)) +
  scale_edge_alpha(range = c(0.3, 1)) +
  guides(edge_width = "none", edge_alpha = "none") +
  theme_graph()

# ggsave("2014_network_plot.png", width = 8, height = 6, dpi = 300)
```

```{r}
## 2019-2021

# convert boot result + averaged network into an undirected graph
nodes_df <- data.frame(name = nodes(avg.2019))
boot_df  <- as.data.frame(boot.2019) 
avg_arcs <- as.data.frame(arcs(avg.2019)) 

edges <- avg_arcs %>%
  left_join(boot_df[, c("from", "to", "strength")],
            by = c("from", "to"))

g <- graph_from_data_frame(edges, directed = FALSE, vertices = nodes_df) 

# strength plot without arrows
set.seed(123)  # for reproducible layout

# create layout
lay <- create_layout(g, layout = "nicely")

# find the row corresponding to siteID
idx_site <- which(lay$name == "siteID")

# compute a horizontal center for the main network (all non-siteID nodes)
center_x <- mean(lay$x[lay$name != "siteID"])

# put siteID above the rest
lay$x[idx_site] <- center_x
lay$y[idx_site] <- max(lay$y) + 0.35

# plot
ggraph(lay) +
  geom_edge_link(aes(width = strength, alpha = strength),
                 color = "black") +
  geom_node_circle(aes(r = 0.3),
                   fill = "white",
                   color = "black",
                   size = 0.2) +
  geom_node_text(aes(label = name),
                 size = 3.5) +
  scale_edge_width(range = c(0.2, 2)) +
  scale_edge_alpha(range = c(0.3, 1)) +
  guides(edge_width = "none", edge_alpha = "none") +
  theme_graph()

# ggsave("2019_network_plot.png", width = 8, height = 6, dpi = 300)
```
